##Forward and Backpropagation
<ここに図を入れる></br>
$\delta_j^{(l)}$ = "error" of cost for $a_j^{(l)}$ (unit j in layer l)

Formally $\delta_j^{(l)}$ = $\dfrac{\partial}{\partial z_j}$cost(i) (for j $\geq$ 0)

cost(i) = $y^{(i)}$log $h_{\theta}(x^{(i)})$ + (1 - $y^{(i)}$)log($1 - h_{\theta}(x^{(i)}))$

##Advanced optimization
function[jVal,gradient] = costFunction(theta)

theta is vectors and equals to initialTheta

optTheta = fminunc(@costFunction, initialTheta, options)

##Neural Network(L=4)
$\Theta^{(1)},\Theta^{(2)},\Theta^{(3)}$ - matrics(Theta1,Theta2,Theta3)  
$D^{(1)},D^{(2)},D^{(3)}$ - matrics($D_1,D_2,D_3$)  
"Unroll" into vectors ベクトルを展開


##Learning Algorithm
Have initial parameters $\Theta^{(1)}$,$\Theta^{(2)}$,$\Theta^{(3)}$
Unroll to get initialTheta to pass to
fminunc(@costFucntion, initialTheta,options)

funcion[jVal,gradientVec] = costFucntion(thetaVec)<br>
    From thetaVec reshape and get $\Theta^{(1)}$,$\Theta^{(2)}$,$\Theta^{(3)}$<br>
    Use forward prop/back prop to compute $D^{(1)}$, $D^{(2)}$,$D^{(3)}$ and J($\Theta$)<br>
    Unroll $D^{(1)}$, $D^{(2)}$,$D^{(3)}$ to get gradientVec

##Gradient Checking
###Numerical estimation of gradients
$$\dfrac{d}{d\theta}J(\theta) \approx \dfrac{J(\theta+\varepsilon)-J(\theta-\varepsilon)}{2\varepsilon}$$
//これをoctaveのコードで表すと

```
gradApprox = (J(theta + EPSILON) - J(theta - EPSILON))/(2*EPSILON)
```

###Parameter vector $\theta$
$$ \theta \in R^n(\theta is "unrolled" version  \Theta^{(1)},\Theta^{(2)},\Theta^{(3)}) $$
$$\theta = [\theta_1,\theta_2,\theta_3,...,\theta_n]$$

$$\dfrac{d}{d\theta_k}J(\theta) \approx \dfrac{J(\theta_1,\theta2,...,\theta_k+\varepsilon,...,\theta_n)-J(\theta_1,\theta2,...,\theta_k-\varepsilon,...,\theta_n)}{2\varepsilon}$$

//これをoctaveで実装すると

```
for i = 1:n,
    thetaPlus = theta;
    thetaPlus(i) = thetaPlus(i) + EPSILON;
    thetaMinus = theta;
    thetaMinus(i) = thetaMinus(i) - EPSILON;
    gradApprox(i) = (J(thetaPlus)-J(thetaMinus))/(2*EPSILON);
end;
```
check gradApprox $\approx$ DVec(backpropagationから導かれた微分)

###Implementation Note:
-Implement backprop to compute DVec(unrolled $D^{(1)}$, $D^{(2)}$,$D^{(3)}$)
-Implement numerical gradient check to compute gradApprox.
-Make sure they give similar values.
-Turn off gradient checking. Using backprop code for learning.

Important:
Be sure to disable your gradient checking code before training your classifier. If you run numerical gradient computation on every iteration of gradient descent(or in the inner loop of costFucntion(...)) your code will be very slow.

##Random Initialization
###Initial value of $\Theta$
for gradient descent and advanced optimization method, need initial value for $\Theta$<br>
`optTheta = fminunc(@costFucntion, initialTheta, options)`

initialThetaの全要素をゼロで定義して論理回帰などのアルゴリズムを走らせると$a^{(2)}_1=a^{(2)}_2$は変わらないため、よい値を導くことはできない。

###Rando Initialization: Symmetry breaking
Initialize each $\Theta^{(l)}_{ij}$ to a random value in [-$\epsilon$,$\epsilon$]

//これをoctaveのコードで書くと

```
Theta1 = rand(10,11)*(2*INIT_EPSILON)-INIT_EPSILON;
Theta2 = rand(1,11)*(2*INIT_EPSILON)-INIT_EPSILON;
```

##Putting it Together
No.of input units :Dimension of features$x^{(i)}$<br>
NO.of output units: Number of classes

###Training a neural network
1.Randomly initialize weights<br>
2.Implement forward propagation to get $h_{\Theta}(x^{(i)})$ for $x^{(i)}$<br>
3.Implement code to compute cost function J($\theta$)
4.Implement backprop to compute partial derivatives $\dfrac{d}{d\theta^{(l)}_{jk}}J(\theta)$

for i =1:m
    perform forward propagation and backpropagation using example($x^{(i)},y^{(i)}$)

5.Use gradient checking to compare $\dfrac{d}{d\theta^{(l)}_{jk}}J(\theta)$ computed using backpropagation vs. using numerical estimate of gradient of $J(\Theta)$<br>
Then disable gradient checking code.

6.Use gradient descent or advanced optimization method with backpropagation to try to minimize $J(\Theta)$ as a function of parameters $\Theta$

###Autonomous Driving
backpropagationによってステアリング操作を数分で理解することができる。現在走っている自動運転の車はもっと頑強なアルゴリズムで動いていると思われるが。

###From:assigment
1.input layer, hiden layer にバイアス項を追加

2.各データセットに対してfeedforward propagationと実際の数字の差分を計算する

$$\delta_{k}^{(3)} = (a_k^{(3)}-y_{k}) $$

3.hidden layerの差分

$$\delta^{(2)} = (\Theta^{(2)})^{T} \delta^{(3)} .* g'(z^{(2)}) $$

4.差分を合計し、バイアス項を削除

$$\Delta^{(l)} = \Delta^{(l)} + \delta^{(l+1)} (a^{(l)})^T $$

delta2のバイアス項を削除するコードは以下の通り

`delta2_excludebias = delta_2(2:end)`

5.上で計算した差分を規格化して偏微分を計算

$$\dfrac{\partial}{\partial \Theta_{ij} = D_ij^{(l)} = \dfrac{1}{m}\Delta_{ij}^{(l)}$$


