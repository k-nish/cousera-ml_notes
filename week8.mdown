##Unsupervised Learning:Introduction

- 教師あり学習
データセットにはデータを示すxとそのデータのラベルを示すyがあり、新しいデータがどのラベルに属しているかを問われる。

- 教師なし学習
データセットにはデータを示すxしかなく、データのラベルを示すyはない。与えられたデータセット内のデータ構造を調べるのに使われる。
	- マーケティングのセグメントを見つけたり、SNS分析で人をグルーピングするのに用いられる。

##K-Means algorithm
###K-Meansとは
データセットを任意の数のグループに分類する手法である。

1. 分類するクラスターの数(k)を決める。
2. k個の重心の座標を決める
3. 重心とのユークリッド距離をすべて計算し、すべてのデータセットに対してどの重心が一番近いか求める
4. クラスタリングしたデータセットの中でそれぞれの平均を求め、新たな重心を決める
5. 重心が動かなくなるまで3.と4.を繰り返す

もしクラスタリングの途中でデータが振り分けられない重心が存在したらその重心を取り除き、k-1個のクラスターに分けるようにするのが普通。

##Optimization Objectiove
以下のように変数をきめる

- $c^{(i)}$:それぞれのデータセットが属するクラスターの番号
- $\mu_k$:k番目の重心
- $\mu_{c^{(i)}}$:i番目のデータセットが属するクラスターの重心

このときK-Meansのコスト関数は次の通りとなる。
$$J(c^{(i)},...,c^{(m)},\mu_1,...,\mu_k) = \dfrac{1}{m} \sum_{i=1}^{m}\|x^{(i)}-\mu_{c^{(i)}}\|^2$$

##Random Initialization
###最初のk個の重心の座標の決め方
最初の座標の決め方によっては、誤ったクラスタリングをしてしまうことがあるので以下の初期化を実行することで正しいクラスタリングをする。

1. データセットの中からk(クラスターの数)個の標本を選び、それぞれを最初のクラスターの重心に設定する
2. k-Meansを実行し目的関数を最小化させる
3. 1.2.を何度も(100回くらい?)実行させコスト関数がグローバル最小となる値を見つける。

##Choosing the Number of Clusters
クラスターの数を最適化する絶対的な手法は存在しない。
1つの方法はエルボー法という方法である。<br>
縦軸にK-Meansのコスト関数、横軸にクラスターの数を設定しコスト関数をプロットする。コスト関数の傾きが大きく変化する点があればそれが最適なクラスターの数となる。

しかし、急激な傾きの変化なくコスト関数が最小化するとき、エルボー法は使えない。
何のためにクラスタリングをしているのかという目的から、クラスターの数を決めることの法が多い。Tシャツのサイズの数を決めるために人の身体データをクラスタリングするときのように。

##Motivation:date compression


##Motivation: Visualization


##Principal Component Analysis Problem Formulation


##Principal Component Analysis Algorithm


##Reconstrucion from Compressed Regression


##Chossing the Number of Principal Components


##Advise for Applying PCA
